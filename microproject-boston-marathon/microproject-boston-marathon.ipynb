{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h1 style=\"text-align: center\">\n",
    "<div style=\"color: #DD3403; font-size: 60%\">Data Science DISCOVERY MicroProject</div>\n",
    "<span style=\"\">MicroProject: Boston Marathon </span>\n",
    "<div style=\"font-size: 60%;\"><a href=\"https://discovery.cs.illinois.edu/microproject/boston-marathon/\">https://discovery.cs.illinois.edu/microproject/boston-marathon/</a></div>\n",
    "</h1>\n",
    "\n",
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Sources: SCORE Sports Data Repository and Boston-Marathon-Data-Project\n",
    "\n",
    "The Boston Marathon is an annual marathon hosted by several cities in greater Boston in eastern Massachusetts, United States, held on Patriots' Day, the third Monday of April. Considered one of the world's oldest and most prestigious marathons, it attracts runners from all over the globe to participate in its challenging course.\n",
    "\n",
    "\n",
    "The [SCORE Sports Data Repository](https://data.scorenetwork.org/) is a curated collection of datasets across various sports, designed for use in statistics and data science education. This repository encourages exploration and analysis, organized by sport and educational topic, and is funded by the National Science Foundationâ€‹ (ScoreNetwork)â€‹.\n",
    "\n",
    "We will be analyzing the [2023 Boston Marathon runners](https://data.scorenetwork.org/running/boston_marathon_2023.html) dataset in this microproject.  In addition to the 2023 dataset, we will be analyzing datasets 2000 and 2010. These datasets are pulled from [Boston-Marathon-Data-Project](https://github.com/adrian3/Boston-Marathon-Data-Project), a public GitHub repository containing Boston Marathon data from 1897-2019."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "The`\"results2000.csv\"`,`\"results2010.csv\"`,`\"results2023.csv\"` files contains data for the 2000, 2010, and 2023 Boston Marathons. Import the datasets using pandas and save them to variables called `df_2000`, `df_2010`, `df_2023`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2000 = ...\n",
    "df_2010 = ...\n",
    "df_2023 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Data Import\n",
    "# - This read-only cell contains a \"checkpoint\" for this section of the MicroProejct and verifies you are on the right track.\n",
    "# - If this cell results in a celebration message, you PASSED all test cases!\n",
    "# - If this cell results in any errors, check you previous cells, make changes, and RE-RUN your code and then this cell.\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "import math\n",
    "assert(\"df_2000\" in vars())\n",
    "assert(\"df_2010\" in vars())\n",
    "assert(\"df_2023\" in vars())\n",
    "assert(len(df_2000) == 15247)\n",
    "assert(len(df_2010) == 22255)\n",
    "assert(len(df_2023) == 26598)\n",
    "assert(\"Moses\" in df_2000[\"first_name\"].values)\n",
    "assert(math.isclose( df_2000[\"seconds\"].mean(), 13290.47871712468 ))\n",
    "assert(\"Tekeste\" in df_2010[\"first_name\"].values)\n",
    "assert(math.isclose( df_2010[\"seconds\"].mean(), 13791.263772804889 ))\n",
    "assert(\"Chebet, Evans\" in df_2023[\"name\"].values)\n",
    "assert(8487.0 in df_2023[\"half_time_sec\"].values)\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1:  Longitudinal Analysis of Finish Times\n",
    "\n",
    "In this puzzle, we're going to explore how the average, median, and variability of finish times have changed over the decades. "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Puzzle 1.1: Creating an integer pace column in each dataframe\n",
    "\n",
    "In order to use all of the datasets together, we need to clean them up and add new columns.  The dataset from 2000 and 2010 have a string `pace` column that contains a string of each runners average pace per mile in minutes (ex: `\"00:04:56\"`).  The 2023 dataset does not have a `pace` column.\n",
    "\n",
    "We can observe this in the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2010.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a `pace_seconds` Column\n",
    "\n",
    "A marathon is exactly `26.21875` miles, so if we want to get the average seconds per mile we would divide the total seconds by 26.21875.  Using the `seconds` column in the 2000 and 2010 dataset, create a column for the pace in seconds in each dataset.  Call this column `pace_seconds`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2000[\"pace_seconds\"] = ...\n",
    "df_2010[\"pace_seconds\"] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Using the `\"finish_net_sec\"` column in the 2023 datset, create a column for the pace in seconds. Call this column `pace_seconds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023[\"pace_seconds\"] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Puzzle 1.1\n",
    "\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "assert( math.isclose( df_2000[\"pace_seconds\"].mean(), 506.90741233371847) )\n",
    "assert( math.isclose( df_2010[\"pace_seconds\"].mean(), 526.0076766743223) )\n",
    "assert( math.isclose( df_2023[\"pace_seconds\"].mean(), 509.22095552185135) )\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Puzzle 1.2: Creating an Average Paces by Age Group DataFrame\n",
    "\n",
    "At this point, you have normalized the datasets so that all three contain `pace_seconds`! ðŸŽ‰  In addition to `pace_seconds`, each dataset also contains the `age_group` that contains a string value of the age group of each participant (ex: `18-39`, `40-44`, etc).\n",
    "\n",
    "We want to explore if the average time in each age group has changed significantly throughout the years.  To do this, we want to create a DataFrame with the following format:\n",
    "\n",
    "|       | 2000 | 2010 | 2023 |\n",
    "| ----- | ---- | ---- | ---- |\n",
    "| 18-39 |  530 |  520 |  510 |\n",
    "| 40-44 |  540 |  530 |  520 |\n",
    "| ...   |  ... |  ... |  ... |\n",
    "\n",
    "There are **many** ways to organize your data like this.  One of the most natural ways is to join the normalized datasets and create a **pivot table**."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a Pivot Table: Preparing the Data\n",
    "\n",
    "A pivot table is a **summary** of a DataFrame created by describing:\n",
    "\n",
    "1. The desired grouping of the rows in the result (the `index` parameter) -- in this case, each row is an `age_group`,\n",
    "2. The desired grouping of the columns in the result (the `columns` parameter) -- in this case, each column is a year,\n",
    "3. The desired data for each cell (the `values` parameter) -- in this case, each cell contains `pace_seconds`, **AND**\n",
    "4. The method how we combine multiple `values` together if there's multiple values (ex: `mean`, `max`, `sum`, etc)\n",
    "\n",
    "We will want to summarize all of our data, so we need to combine our three DataFrames into a single DataFrame.  Before we do that, currently, each of our DataFrames do not contain data about the year that the data contained in the DataFrame is about.\n",
    "\n",
    "Add a new column `year` to all three DataFrames that specifies the year in which the DataFrame is from:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a \"year\" column to all three DataFrames:"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, concatenate all three DataFrames together to create one large DataFrame called `df`:\n",
    "\n",
    "> Not sure how to combine the DataFrames?  The DISCOVERY guide [Combining DataFrames by Concatenation](https://discovery.cs.illinois.edu/guides/Combining-DataFrames/Combining-DataFrames-by-Concatenation/) can help you out here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ...\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Puzzle 1.2: Creating a Pivot Table: Preparing the Data\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "import math\n",
    "assert(\"df\" in vars())\n",
    "assert(\"year\" in df)\n",
    "assert(\"pace_seconds\" in df)\n",
    "assert(math.isclose( df[\"pace_seconds\"].mean(), 514.4986837163259 ))\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a Pivot Table: Create the Pivot Table\n",
    "\n",
    "Finally, let's create the pivot table!\n",
    "\n",
    "You will need to identify the four features we need in the pivot table.  The first three parameters (`index`, `columns`, and `values`) is the **name of the column in the DataFrame**.  Refer back to the beginning of this section for a reminder of the purpose of these three parameters.\n",
    "\n",
    "Since we're calculating the **average pace for each age group**, the `aggfunc` is provided for you as `\"mean\"`.  Complete the below code to create the `summary`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.pivot_table(\n",
    "  index = ...,       # What grouping of data do we want in the rows of our result?\n",
    "  columns = ...,     # What grouping of data do we want in the columns of our result?\n",
    "  values = ...,      # What grouping of data do we want in the cells of our result?\n",
    "  aggfunc = \"mean\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Puzzle 1.2: Creating a Pivot Table: Create the Pivot Table\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "import math\n",
    "assert(\"summary\" in vars())\n",
    "assert(2010 in summary or \"2010\" in summary)\n",
    "assert(math.isclose(summary.loc[\"18-39\"].mean(), 498.07999608132303 ))\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Puzzle 1.3: Visualizing the Result\n",
    "\n",
    "Using your `summary` DataFrame, create a simple line chart using `summary.plot.line()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a line char to the `summary` DataFrame:\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Does it seem like marathon runners have improved over the years?"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 2: Visualizing the Fastest Finish"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modify the code you used to create a `summary` to create a new `summary_fastest` that, instead of finding the **average** pace, find  the **fastest pace** by each age group for each year.  *(Hint: `aggfunc` may help you here!)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_fastest = ...\n",
    "summary_fastest"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize the Result\n",
    "\n",
    "Let's see if this data looks different using the same visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_fastest.plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Puzzle 2: Fastest Time\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "assert(math.isclose(summary_fastest.loc[\"18-39\"].mean(), 291.0512514898689 ))\n",
    "assert(math.isclose(summary_fastest.loc[\"40-44\"].std(), 7.526989423234205 ))\n",
    "print(f\"{tada} All Tests Passed! {tada}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submission\n",
    "\n",
    "You're almost done!  All you need to do is to commit your lab to GitHub and run the GitHub Actions Grader:\n",
    "\n",
    "1.  âš ï¸ **Make certain to save your work.** âš ï¸ To do this, go to **File => Save All**\n",
    "\n",
    "2.  After you have saved, exit this notebook and return to https://discovery.cs.illinois.edu/microproject/boston-marathon/ and complete the section **\"Commit and Grade Your Notebook\"**.\n",
    "\n",
    "3. If you see a 100% grade result on your GitHub Action, you've completed this MicroProject! ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
