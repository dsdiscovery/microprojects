{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h1 style=\"text-align: center\">\n",
    "<div style=\"color: #DD3403; font-size: 60%\">Data Science DISCOVERY MicroProject</div>\n",
    "<span style=\"\">MicroProject: Building a Scene Recognition Model form Video Frames</span>\n",
    "<div style=\"font-size: 60%;\"><a href=\"https://discovery.cs.illinois.edu/microproject/video-frame-scene-recognition-model/\">https://discovery.cs.illinois.edu/microproject/video-frame-scene-recognition-model/</a></div>\n",
    "</h1>\n",
    "\n",
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Source: Frames of a Video\n",
    "\n",
    "Visual images are an important part of all media and Data Scientists are often using images as data sources.  In this MicroProject, you will create a simple model to detect the amount of time spent in two different \"scenes\" we used when creating office-hour style videos for Data Science DISCOVERY.\n",
    "\n",
    "*This MicroProject was inspired by a podcast that we recently recorded with the team from the Center for Innovation in Teaching and Learning who helped produce our video.  To learn the background and hear from Karle and Wade about the journey of creating DISCOVERY, go over and listen to our episode on the \"Teach Talk Listen Learn Podcast\" where talk with TTLL host Bob Dignan and our CITL video producer Eric Schumacher: https://citl.illinois.edu/citl-101/teaching-learning/teach-talk-listen-learn*\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading a Video Frame\n",
    "\n",
    "We have provided you with one frame every second from our video [*\"Outliers Impact on Correlation (m6-02b)\"*](https://www.youtube.com/watch?v=bd6hQ2UcIJc) that is used as part of our [DISCOVERY lecture covering Correlation](https://discovery.cs.illinois.edu/learn/Towards-Machine-Learning/Correlation/).\n",
    "\n",
    "The `skimage` library is commonly used to load image data into Python.  Specifically:\n",
    "\n",
    "- `skimage.io.imread(filename)` will read a filename and return the pixel color for every pixel in the image.\n",
    "- To use the `imread` function, you will need to either do one of the following:\n",
    "\n",
    "    1. Either import all of `sklearn` by using the import line `import sklearn`.  After importing all of `sklearn`, you will call the function using it's fully qualified name: `skimage.io.imread(filename)`.\n",
    "    \n",
    "    **OR**\n",
    "    \n",
    "    2. Import only the `imread` function by using the import line `from sklearn.io import imread`.  After importing only `imread`, you will call the function directly: `imread(filename)`\n",
    "\n",
    "#### Read Pixel Data for `frames/frame_0001.jpg`\n",
    "\n",
    "We have provided a `frames` directory with all of the frames.  In the following cell, store the pixel color data from the file named `frames/frame_0001.png` image in the variable `pixels` by using the `imread` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ðŸ”¬ Checkpoint Tests ðŸ”¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Reading Video Frames\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"pixels\" in vars())\n",
    "assert(pixels.shape == (360, 640, 3))\n",
    "assert(pixels[0][0][0] == 91)\n",
    "\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 1: Storing Average Pixel Color\n",
    "\n",
    "The **shape** of your data is the `rows` by `columns` by `color values` as 3-dimensional list.  Here's a formatted view of your `pixels` data:\n",
    "\n",
    "```\n",
    "[\n",
    "  [ [91, 83, 80], [91, 83, 80], [91, 83, 80] ], ... ],   # Row #1\n",
    "  [ [91, 83, 80], [91, 83, 80], [91, 83, 80] ], ... ],   # Row #2\n",
    "  ...                                                    # ...\n",
    "]\n",
    "```\n",
    "\n",
    "The current shape of `pixels` is 360 rows by 640 columns by 3 colors.  Each of the three colors represent the three color channels on a screen: red, green, and blue.\n",
    "\n",
    "Using `pixel.mean()`, we find the average color grouping **ALL** the color channels (combining blues and reds and greens together).  Try it out:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = pixels.reshape(-1, 3)\n",
    "pixels\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "To find the average of each color channel, the `pixels.resize(-1, 3).mean(axis=0)` function will find the mean of everything **except** the color channels.  Check out the new mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels.mean(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 1.1: Finding the Average Color of One Image\n",
    "\n",
    "Store `pixel`'s average red value in `r`, average green value in `g`, and average blue value in `b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Puzzle 1.1: Finding the Average Color of One Image\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "import math\n",
    "assert(\"r\" in vars())\n",
    "assert(\"g\" in vars())\n",
    "assert(\"b\" in vars())\n",
    "assert(math.isclose(r, 88.65917534722222))\n",
    "assert(math.isclose(g, 67.45620225694445))\n",
    "assert(math.isclose(b, 60.42497829861111))\n",
    "\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Puzzle 1.2: Finding the Average Color of All Images\n",
    "\n",
    "The following code loops through every file in the `frames` directory -- this will include `frame_0001.jpg` (like you analyzed already) and also `frame_0002.jpg`, `frame_0003.jpg`, and all 300+ frames!\n",
    "\n",
    "Create a DataFrame where each row is one frame with the following four columns:\n",
    "- `frame`, the filename of the frame\n",
    "- `r`, the average red color of the frame\n",
    "- `g`, the average green color of the frame\n",
    "- `b`, the average blue color of the frame\n",
    "\n",
    "The structure of the code should be nearly identical to writing a simulation.  Instead of creating random variables for your real world data, your real world data will be the filename, and the average color values.\n",
    "\n",
    "- See: https://discovery.cs.illinois.edu/learn/Simulation-and-Distributions/Simple-Simulations-in-Python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "for frame in glob.glob(os.path.join(\"frames\", \"*.jpg\")): \n",
    "  # `frame`` contains the filename of the frame (ex: \"frames/frame_0001.jpg\").  Use it for `imread` to read the frame image data.\n",
    "  ...\n",
    "\n",
    "df = ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ðŸ”¬ Checkpoint Tests ðŸ”¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Puzzle 1.2: Finding the Average Color of All Images\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "import math\n",
    "assert(\"df\" in vars())\n",
    "assert(len(df) == 330)\n",
    "assert(\"r\" in df)\n",
    "assert(\"g\" in df)\n",
    "assert(\"b\" in df)\n",
    "assert(\"frame\" in df)\n",
    "assert( abs( df[ df.frame.str.endswith(\"_0001.jpg\") ][\"r\"].sum() - 88 ) < 1 )\n",
    "\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 2: Create a Simple Classifier\n",
    "\n",
    "In the DISCOVERY lecture videos, there are two primary \"scenes\" in the video:\n",
    "\n",
    "1. **\"Office Hours Studio Scene\"**, where Karle and Wade are talking to each other and the audience,\n",
    "\n",
    "2. **\"Notebook Scene\"**, where the notebook is displayed\n",
    "\n",
    "View the `frames` folder on your computer and find **at least three more frames** that are in the \"office hours studio scene\" and **at least three more frames** that are in the \"notebook scene\".  Add the frames you found to the list below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of at least four office hour frames by the filename's frame number:\n",
    "office_hour_frames = [1, ...]\n",
    "\n",
    "# List of at least four notebook frames by the filename's frame number:\n",
    "notebook_frames = [30, ...]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Observing the Average Colors of Your Frames\n",
    "\n",
    "The following code uses your sample frames to display the average color values for your selected frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"== Office Hour Frames ==\")\n",
    "print( df[ df[\"frame\"].isin( [f\"frames\\\\frame_{frame:04d}.jpg\" for frame in office_hour_frames] ) ] )\n",
    "print()\n",
    "print(\"== Notebook Frames ==\")\n",
    "print( df[ df[\"frame\"].isin( [f\"frames\\\\frame_{frame:04d}.jpg\" for frame in notebook_frames] ) ] )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Your Classifier Function\n",
    "\n",
    "A **classifier function** is a function that takes data and gives a classification for that data.  Create a new function, `classifyFrame` that receives an `r`, `g`, and `b` value.\n",
    "\n",
    "Using information from your frames above, have the function return the string `\"office hour\"` or `\"notebook\"` based on the values of `r`, `g`, and `b`.\n",
    "\n",
    "**IMPORTANT**: Make sure your classifier can handle **ANY** input -- even frames you have not seen before!  For example, you might decide that you will call a frame an `\"office hour\"` frame if the sum of `r`, `g` and `b` is greater than 100 and otherwise it's a `\"notebook\"` scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyFrame(r, g, b):\n",
    "  # Return either \"office hour\" or \"notebook\" based on the values of `r`, `g`, and `b`.\n",
    "  ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ðŸ”¬ Checkpoint Tests ðŸ”¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Part 2: Create a Simple Classifier\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "r = classifyFrame(0, 0, 0)\n",
    "assert(r == \"notebook\" or r == \"office hour\")\n",
    "\n",
    "r = classifyFrame(255, 255, 255)\n",
    "assert(r == \"notebook\" or r == \"office hour\")\n",
    "\n",
    "r = classifyFrame(0, 255, 255)\n",
    "assert(r == \"notebook\" or r == \"office hour\")\n",
    "\n",
    "r = classifyFrame(255, 255, 0)\n",
    "assert(r == \"notebook\" or r == \"office hour\")\n",
    "\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 3: Using Your Classifier!\n",
    "\n",
    "Now that we have a classifier, we should run it on every frame!\n",
    "\n",
    "The following cell runs your `classifyFrame` classifier on every frame and adds a new column `scene` and displayed 20 random rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"scene\"] = df.apply(lambda row: classifyFrame(row.r, row.g, row.b), axis=1)\n",
    "df.sample(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ðŸ”¬ Checkpoint Tests ðŸ”¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Part 3: Using Your Classifier\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"scene\" in df)\n",
    "\n",
    "assert(len(df[ df.scene == \"notebook\" ]) > 100)\n",
    "assert(len(df[ df.scene == \"office hour\" ]) > 75)\n",
    "assert(len(df[ df.scene == \"notebook\" ]) + len(df[ df.scene == \"office hour\" ]) == len(df))\n",
    "\n",
    "assert( len( df[ (df.frame.str.endswith(\"0001.jpg\")) & (df.scene == \"office hour\") ] ) == 1 )\n",
    "assert( len( df[ (df.frame.str.endswith(\"0306.jpg\")) & (df.scene == \"office hour\") ] ) == 1 )\n",
    "assert( len( df[ (df.frame.str.endswith(\"0081.jpg\")) & (df.scene == \"notebook\") ] ) == 1 )\n",
    "assert( len( df[ (df.frame.str.endswith(\"0191.jpg\")) & (df.scene == \"notebook\") ] ) == 1 )\n",
    "\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Observing Results\n",
    "\n",
    "In the next 5 cells, we display a frame and you'll run code to check what your classifier classified the frame as being!  Make sure to run the code for each frame:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Frame #0001: Office Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ df.frame.str.endswith(\"0001.jpg\") ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "![Frame 0001](frames/frame_0001.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Frame #0081: Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ df.frame.str.endswith(\"0081.jpg\") ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "![Frame 0001](frames/frame_0081.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Frame #0191: Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ df.frame.str.endswith(\"0191.jpg\") ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "![Frame 0001](frames/frame_0191.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Frame #0306: Office Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ df.frame.str.endswith(\"0306.jpg\") ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "![Frame 0001](frames/frame_0306.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Frame #0320: Data Science Duo Logo???\n",
    "\n",
    "What did you classify the DUO logo as?  It's nether one, but we don't have that option!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ df.frame.str.endswith(\"0320.jpg\") ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "![Frame 0001](frames/frame_0320.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Frame #328: Video Credits\n",
    "\n",
    "What did you classify the DUO logo as?  It's another tricky one!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ df.frame.str.endswith(\"0328.jpg\") ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "![Frame 0328](frames/frame_0328.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 4: Update Your Classifier to Account with an \"Other\" Category\n",
    "\n",
    "Create a second classifier -- `classifyFrame2` -- that returns either `\"notebook\"`, `\"office hour\"` or `\"other\"`.  Your classifier should correctly handle the \"Data Science Duo\" (ex: #0320) frames and the \"Credit\" frames (ex: #0328)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyFrame2(r, g, b):\n",
    "  # Return either \"office hour\", \"notebook\", or \"other\" based on the values of `r`, `g`, and `b`.\n",
    "  ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply your `classifyFrame2` function\n",
    "\n",
    "Using `classifyFrame2`, this code replaces the value in the column `scene` with your `classifyFrame2` classification function.  The output of this cell shows the last frames of the video, which we expect to be `\"other\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"scene\"] = df.apply(lambda row: classifyFrame2(row.r, row.g, row.b), axis=1)\n",
    "df.tail(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ðŸ”¬ Checkpoint Tests ðŸ”¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Part 4: Update Your Classifier to Account with an Other Category\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert(\"scene\" in df)\n",
    "\n",
    "assert(len(df[ df.scene == \"notebook\" ]) > 100)\n",
    "assert(len(df[ df.scene == \"office hour\" ]) > 75)\n",
    "assert(len(df[ df.scene == \"other\" ]) >= 15)\n",
    "assert(len(df[ df.scene == \"other\" ]) <= 18)   # Okay to classify the intro screens as well, but not any others.\n",
    "assert(len(df[ df.scene == \"notebook\" ]) + len(df[ df.scene == \"office hour\" ]) + len(df[ df.scene == \"other\" ]) == len(df))\n",
    "\n",
    "assert( len( df[ (df.frame.str.endswith(\"0001.jpg\")) & (df.scene == \"office hour\") ] ) == 1 )\n",
    "assert( len( df[ (df.frame.str.endswith(\"0306.jpg\")) & (df.scene == \"office hour\") ] ) == 1 )\n",
    "assert( len( df[ (df.frame.str.endswith(\"0081.jpg\")) & (df.scene == \"notebook\") ] ) == 1 )\n",
    "assert( len( df[ (df.frame.str.endswith(\"0191.jpg\")) & (df.scene == \"notebook\") ] ) == 1 )\n",
    "assert( len( df[ (df.frame.str.endswith(\"0317.jpg\")) & (df.scene == \"other\") ] ) == 1 )\n",
    "assert( len( df[ (df.frame.str.endswith(\"0325.jpg\")) & (df.scene == \"other\") ] ) == 1 )\n",
    "assert( len( df[ (df.frame.str.endswith(\"0328.jpg\")) & (df.scene == \"other\") ] ) == 1 )\n",
    "\n",
    "print(f\"{tada} All Tests Passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submission\n",
    "\n",
    "You're almost done!  All you need to do is to commit your lab to GitHub and run the GitHub Actions Grader:\n",
    "\n",
    "1.  âš ï¸ **Make certain to save your work.** âš ï¸ To do this, go to **File => Save All**\n",
    "\n",
    "2.  After you have saved, exit this notebook and return to https://discovery.cs.illinois.edu/microproject/video-frame-scene-recognition-model/ and complete the section **\"Commit and Grade Your Notebook\"**.\n",
    "\n",
    "3. If you see a 100% grade result on your GitHub Action, you've completed this MicroProject! ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
